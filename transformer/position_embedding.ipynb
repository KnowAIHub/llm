{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "71e8d9fa-dfce-41da-9c85-eb1191060c2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x:\n",
      "tensor([[[0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0.]]])\n",
      "PE:\n",
      "tensor([[[ 0.0000,  1.0000,  0.0000,  1.0000],\n",
      "         [ 0.8415,  0.5403,  0.0100,  0.9999],\n",
      "         [ 0.9093, -0.4161,  0.0200,  0.9998],\n",
      "         [ 0.1411, -0.9900,  0.0300,  0.9996],\n",
      "         [-0.7568, -0.6536,  0.0400,  0.9992],\n",
      "         [-0.9589,  0.2837,  0.0500,  0.9988],\n",
      "         [-0.2794,  0.9602,  0.0600,  0.9982],\n",
      "         [ 0.6570,  0.7539,  0.0699,  0.9976],\n",
      "         [ 0.9894, -0.1455,  0.0799,  0.9968],\n",
      "         [ 0.4121, -0.9111,  0.0899,  0.9960]]])\n",
      "output:\n",
      "tensor([[[ 0.0000,  1.0000,  0.0000,  1.0000],\n",
      "         [ 0.8415,  0.5403,  0.0100,  0.9999],\n",
      "         [ 0.9093, -0.4161,  0.0200,  0.9998],\n",
      "         [ 0.1411, -0.9900,  0.0300,  0.9996],\n",
      "         [-0.7568, -0.6536,  0.0400,  0.9992]],\n",
      "\n",
      "        [[ 0.0000,  1.0000,  0.0000,  1.0000],\n",
      "         [ 0.8415,  0.5403,  0.0100,  0.9999],\n",
      "         [ 0.9093, -0.4161,  0.0200,  0.9998],\n",
      "         [ 0.1411, -0.9900,  0.0300,  0.9996],\n",
      "         [-0.7568, -0.6536,  0.0400,  0.9992]]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import math\n",
    "\n",
    "# 位置编码模块\n",
    "class PositionalEncoding(nn.Module):\n",
    "    # 传入最大位置长度max_pos和词向量的维度embed_dim\n",
    "    def __init__(self, max_pos, embed_dim):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        # 初始化位置编码矩阵，全部为零\n",
    "        PE = torch.zeros(max_pos, embed_dim)  # 保存位置编码的数组\n",
    "        # 生成从0到max_pos-1的位置数组pos\n",
    "        pos = torch.arange(0, max_pos).unsqueeze(1).float()\n",
    "\n",
    "        # 从0开始，生成间隔为2的序列，对应公式中的2i\n",
    "        multi_term = torch.arange(0, embed_dim, 2).float()\n",
    "        # 计算公式中pos对应的系数部分\n",
    "        # 这里计算的是e^(2i * (-log(10000/d)))\n",
    "        # 它从数学计算上等价于1 / (10000^(2i/d))\n",
    "        multi_term = torch.exp(multi_term * (-math.log(10000.0) / embed_dim))\n",
    "        # 使用正弦函数sin和余弦函数cos，生成位置编码数组PE\n",
    "        PE[:, 0::2] = torch.sin(pos * multi_term)\n",
    "        PE[:, 1::2] = torch.cos(pos * multi_term)\n",
    "\n",
    "        # 将数组PE注册为一个不需要梯度更新的缓存数组\n",
    "        # 相当于将位置信息保存在了一个常量数组中\n",
    "        self.register_buffer('PE', PE.unsqueeze(0))\n",
    "\n",
    "    # 前向传播函数，函数传入输入数据x\n",
    "    def forward(self, x):\n",
    "        # 将x加上位置信息PE\n",
    "        return x + self.PE[:, :x.size(1)].clone().detach()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    max_pos = 10  # 最大序列长度\n",
    "    embed_dim = 4  # 词向量维度\n",
    "\n",
    "    # 定义位置编码模型\n",
    "    model = PositionalEncoding(max_pos, embed_dim)\n",
    "\n",
    "    # 输入数据，代表了2个样本，每个样本长度是5\n",
    "    x = torch.zeros(2, 5, embed_dim)\n",
    "\n",
    "    # 将x传入模型model，计算添加位置信息信息的结果output\n",
    "    output = model(x)\n",
    "\n",
    "    print(\"x:\")\n",
    "    print(x)\n",
    "    print(\"PE:\")\n",
    "    print(model.PE)\n",
    "    print(\"output:\")\n",
    "    print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "236b0786-7733-454e-a2b6-527b13a9e81a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
