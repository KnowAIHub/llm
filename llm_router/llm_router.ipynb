{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "32ef6fa8-2be0-4316-b96f-7061b91281d3",
   "metadata": {},
   "source": [
    "大型语言模型已经改变了业务，在从自然语言理解到复杂推理等各种任务中都表现出令人印象深刻的性能。然而，部署这些模型往往需要在性能和成本之间取得平衡。像 GPT-4o 这样的高级模型具有很高的准确性，但计算成本和财务成本也很高。这给对成本敏感的应用带来了挑战，因为在这些应用中，既要保证质量，又要控制成本是至关重要的。\n",
    "\n",
    "## 什么是LLM Router\n",
    "\n",
    "LLM 路由器是一个根据任务的复杂性动态地将查询定向到最合适的大型语言模型的系统。它将更简单的查询发送到更小、更具成本效益的模型，同时为更强大的模型保留复杂的任务，平衡性能和成本。\n",
    "\n",
    "## 什么时候需要LLM Router\n",
    "\n",
    "在需要平衡性能质量与成本限制的应用程序中部署 LLM 时，您需要 LLM 路由器。这在查询复杂性差异很大的场景中尤其重要，例如在聊天机器人、客户服务系统和其他交互式人工智能解决方案中。\n",
    "\n",
    "如果所有查询都发送到 GPT-4o 等高性能模型，成本很快就会变得令人望而却步。当您想要保持高质量的响应而又不想为每次交互使用强大的模型而承担全部费用时，LLM 路由器非常有用。通过将查询路由到最合适的模型，系统可以降低成本，同时保持可接受的性能水平，使其成为仍需要准确和及时响应的成本敏感型应用程序的理想选择。\n",
    "\n",
    "## LLM Router如何工作\n",
    "\n",
    "LLM 路由器的工作原理是了解哪些类型的查询在由较弱的模型处理时更有可能产生有利的结果。在训练期间，路由器会接触到查询示例以及路由到强模型或弱模型时相应的性能结果。通过分析这些模式，路由器学会识别通常需要更强大的模型才能获得高质量结果的查询特征。\n",
    "\n",
    "当新查询到达时，路由器使用学到的知识来预测每个模型成功的可能性。如果查询类似于之前通过强模型获得更好结果的查询，则路由器会将其定向到那里。相反，如果较弱的模型可能足以处理查询，则会相应地路由它。这种动态决策过程可以优化性能，同时控制成本，确保每个查询都由最适合的模型处理，从而根据过去的经验提供有利的结果。\n",
    "\n",
    "## 训练一个LLM Router\n",
    "\n",
    "现在，我们将专注于开发大型语言模型的路由系统，通过训练分类器来决定查询是否应该由强大的模型（例如 GPT-4o）或较弱的、具有成本效益的模型（例如 Mixtral-8x7B）处理。为了优化路由决策，我们利用包含 GPT-4o 和 Mixtral 响应的数据集，根据 Mixtral 的答案与 GPT-4o 响应的匹配程度，按 1 到 5 的等级进行评分。\n",
    "\n",
    "听起来可能有点奇怪，我们使用 GPT-4o 来评估 GPT-4o 和 Mixtral 生成的响应的质量（GPT-4o 将其自己的答案与另一个模型进行比较）。然而，由于我们要求模型比较 Mixtral 响应与 GPT-4o 响应的匹配程度，我相信模型偏向其自身响应的风险较小，因为它只是比较 Mixtral 响应的匹配程度GPT-4o 响应。\n",
    "\n",
    "评分为 4 或更高的响应被认为足以满足较弱的模型，而评分低于 4 的响应则表明需要更强的模型。此代码训练一个学习这些路由模式的二元分类器。使用 Torch 和 Sentence Transformers 库，对模型进行训练，以根据其对齐分数来预测查询是否应路由到较弱或较强的模型，旨在在不牺牲性能的情况下最大限度地降低成本。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c37fdba8-ec28-4ee8-8700-8b3adb8ca2cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.12/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:13: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mwangrongsheng\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/root/wandb/run-20241007_224043-yvc5r9cg</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/wangrongsheng/router/runs/yvc5r9cg' target=\"_blank\">glamorous-snow-17</a></strong> to <a href='https://wandb.ai/wangrongsheng/router' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/wangrongsheng/router' target=\"_blank\">https://wandb.ai/wangrongsheng/router</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/wangrongsheng/router/runs/yvc5r9cg' target=\"_blank\">https://wandb.ai/wangrongsheng/router/runs/yvc5r9cg</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "100%|██████████| 6/6 [00:20<00:00,  3.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Validation Loss: 0.6845, Initial Validation Accuracy: 0.8638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datasets import load_dataset\n",
    "import wandb  # Import W&B\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Initialize W&B\n",
    "wandb.init(project=\"router\")  # Set your project name\n",
    "\n",
    "# Load the dataset from Hugging Face\n",
    "dataset = load_dataset(\"./gpt4_dataset\") # wangrongsheng/gpt4_dataset\n",
    "\n",
    "# Convert the training data to pandas DataFrame for easier manipulation\n",
    "train_df = dataset[\"train\"].to_pandas()\n",
    "\n",
    "# Define the scoring threshold for routing labels\n",
    "train_df[\"routing_label\"] = train_df[\"mixtral_score\"].apply(lambda x: 0 if x >= 4 else 1)  # Binary classification labels\n",
    "\n",
    "# Extract prompts and labels for training\n",
    "sentences = train_df[\"prompt\"].tolist()\n",
    "labels = train_df[\"routing_label\"].tolist()\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "sentences_train, sentences_val, labels_train, labels_val = train_test_split(sentences, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a custom PyTorch dataset\n",
    "class TrainingDataset(Dataset):\n",
    "    def __init__(self, sentences, labels):\n",
    "        self.sentences = sentences\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sentences)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sentence = self.sentences[idx]\n",
    "        label = self.labels[idx]\n",
    "        return sentence, torch.tensor(label, dtype=torch.float)  # Use float for BCEWithLogitsLoss\n",
    "\n",
    "# Create DataLoaders\n",
    "train_data = TrainingDataset(sentences_train, labels_train)\n",
    "val_data = TrainingDataset(sentences_val, labels_val)\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=4096)\n",
    "val_loader = DataLoader(val_data, batch_size=4096, shuffle=True)  # Validation loader remains unchanged\n",
    "\n",
    "# Define the classifier model with trainable transformer backbone\n",
    "class Classifier(nn.Module):\n",
    "    def __init__(self, transformer_model_name):\n",
    "        super(Classifier, self).__init__()\n",
    "        self.transformer = SentenceTransformer(transformer_model_name)\n",
    "        self.fc1 = nn.Linear(self.transformer.get_sentence_embedding_dimension(), 512)\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.fc3 = nn.Linear(256, 1)  # Single output neuron for binary classification\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, sentences):\n",
    "        embeddings = self.transformer.encode(sentences, convert_to_tensor=True)  # Generate embeddings in the forward pass\n",
    "        x = self.relu(self.fc1(embeddings))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        logits = self.fc3(x)  # Output single logit for binary classification\n",
    "        return logits\n",
    "\n",
    "# Initialize the classifier\n",
    "model = Classifier(transformer_model_name='./all-distilroberta-v1')\n",
    "\n",
    "# Use GPU if it's available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.BCEWithLogitsLoss()  # Use BCEWithLogitsLoss for binary classification with one output neuron\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Number of epochs\n",
    "n_epochs = 10\n",
    "\n",
    "# Directory to save the best model\n",
    "runs_dir = \"runs\"\n",
    "os.makedirs(runs_dir, exist_ok=True)\n",
    "\n",
    "# Initialize best validation loss with infinity\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "# Log hyperparameters to W&B\n",
    "wandb.config = {\n",
    "    \"learning_rate\": 0.001,\n",
    "    \"epochs\": n_epochs,\n",
    "    \"batch_size\": 4096,\n",
    "}\n",
    "\n",
    "def validate(model, val_loader, criterion, device):\n",
    "    \"\"\"Perform validation and return the loss, accuracy, and percentage of predictions for each class.\"\"\"\n",
    "    model.eval()\n",
    "    valid_loss = 0.0\n",
    "    valid_correct = 0\n",
    "    total_predictions = []\n",
    "    with torch.no_grad():\n",
    "        for sentences, labels in tqdm(val_loader):\n",
    "            sentences = list(sentences)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(sentences).squeeze(1)\n",
    "            \n",
    "            # Compute loss\n",
    "            loss = criterion(outputs, labels)\n",
    "            valid_loss += loss.item()\n",
    "            predictions = torch.round(torch.sigmoid(outputs))\n",
    "            valid_correct += (predictions == labels).sum().item()\n",
    "            total_predictions.extend(predictions.cpu().numpy())\n",
    "\n",
    "    valid_loss /= len(val_loader)\n",
    "    valid_accuracy = valid_correct / len(val_loader.dataset)\n",
    "    \n",
    "    return valid_loss, valid_accuracy\n",
    "\n",
    "# Initial validation of the untrained model\n",
    "initial_valid_loss, initial_valid_accuracy = validate(model, val_loader, criterion, device)\n",
    "print(f'Initial Validation Loss: {initial_valid_loss:.4f}, Initial Validation Accuracy: {initial_valid_accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a3c46bd-9b81-4366-9849-38357e2ebc92",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 22/22 [01:21<00:00,  3.71s/it]\n",
      "100%|██████████| 6/6 [00:20<00:00,  3.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Training Loss: 0.5026, Training Accuracy: 0.8650, Validation Loss: 0.3888, Validation Accuracy: 0.8638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 22/22 [01:22<00:00,  3.75s/it]\n",
      "100%|██████████| 6/6 [00:20<00:00,  3.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10, Training Loss: 0.3741, Training Accuracy: 0.8650, Validation Loss: 0.3659, Validation Accuracy: 0.8638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 22/22 [01:23<00:00,  3.81s/it]\n",
      "100%|██████████| 6/6 [00:21<00:00,  3.57s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10, Training Loss: 0.3567, Training Accuracy: 0.8650, Validation Loss: 0.3554, Validation Accuracy: 0.8638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 22/22 [01:23<00:00,  3.79s/it]\n",
      "100%|██████████| 6/6 [00:20<00:00,  3.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10, Training Loss: 0.3489, Training Accuracy: 0.8650, Validation Loss: 0.3535, Validation Accuracy: 0.8638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 22/22 [01:23<00:00,  3.80s/it]\n",
      "100%|██████████| 6/6 [00:20<00:00,  3.44s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10, Training Loss: 0.3440, Training Accuracy: 0.8650, Validation Loss: 0.3535, Validation Accuracy: 0.8638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 22/22 [01:22<00:00,  3.77s/it]\n",
      "100%|██████████| 6/6 [00:20<00:00,  3.49s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10, Training Loss: 0.3394, Training Accuracy: 0.8650, Validation Loss: 0.3499, Validation Accuracy: 0.8638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 22/22 [01:22<00:00,  3.76s/it]\n",
      "100%|██████████| 6/6 [00:20<00:00,  3.43s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10, Training Loss: 0.3346, Training Accuracy: 0.8650, Validation Loss: 0.3486, Validation Accuracy: 0.8638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 1/22 [00:06<02:11,  6.26s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 20\u001b[0m\n\u001b[1;32m     17\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# Forward pass\u001b[39;00m\n\u001b[0;32m---> 20\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43msentences\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# Squeeze output to match shape [batch_size]\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# Compute loss\u001b[39;00m\n\u001b[1;32m     23\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[1], line 62\u001b[0m, in \u001b[0;36mClassifier.forward\u001b[0;34m(self, sentences)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, sentences):\n\u001b[0;32m---> 62\u001b[0m     embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransformer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43msentences\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert_to_tensor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Generate embeddings in the forward pass\u001b[39;00m\n\u001b[1;32m     63\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc1(embeddings))\n\u001b[1;32m     64\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc2(x))\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/sentence_transformers/SentenceTransformer.py:597\u001b[0m, in \u001b[0;36mSentenceTransformer.encode\u001b[0;34m(self, sentences, prompt_name, prompt, batch_size, show_progress_bar, output_value, precision, convert_to_numpy, convert_to_tensor, device, normalize_embeddings, **kwargs)\u001b[0m\n\u001b[1;32m    588\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoken_type_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m features:\n\u001b[1;32m    589\u001b[0m             features[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoken_type_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat(\n\u001b[1;32m    590\u001b[0m                 (\n\u001b[1;32m    591\u001b[0m                     features[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoken_type_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    594\u001b[0m                 \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m    595\u001b[0m             )\n\u001b[0;32m--> 597\u001b[0m features \u001b[38;5;241m=\u001b[39m \u001b[43mbatch_to_device\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    598\u001b[0m features\u001b[38;5;241m.\u001b[39mupdate(extra_features)\n\u001b[1;32m    600\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/sentence_transformers/util.py:1035\u001b[0m, in \u001b[0;36mbatch_to_device\u001b[0;34m(batch, target_device)\u001b[0m\n\u001b[1;32m   1033\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m batch:\n\u001b[1;32m   1034\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(batch[key], Tensor):\n\u001b[0;32m-> 1035\u001b[0m         batch[key] \u001b[38;5;241m=\u001b[39m \u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarget_device\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1036\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m batch\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;34mwandb\u001b[0m: 🚀 View run \u001b[33mglamorous-snow-17\u001b[0m at: \u001b[34mhttps://wandb.ai/wangrongsheng/router/runs/yvc5r9cg\u001b[0m\n",
      "\u001b[1;34mwandb\u001b[0m: Find logs at: \u001b[1;35mwandb/run-20241007_224043-yvc5r9cg/logs\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "wandb.log({\n",
    "    \"epoch\": 0,\n",
    "    \"valid_loss\": initial_valid_loss,\n",
    "    \"valid_accuracy\": initial_valid_accuracy,\n",
    "})\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    # Training\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    train_correct = 0\n",
    "    for sentences, labels in tqdm(train_loader):\n",
    "        sentences = list(sentences)  # Convert tensor of strings back to list for transformer\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # Clear the gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(sentences).squeeze(1)  # Squeeze output to match shape [batch_size]\n",
    "        \n",
    "        # Compute loss\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "        predictions = torch.round(torch.sigmoid(outputs))  # Convert logits to probabilities and then round to 0 or 1\n",
    "        train_correct += (predictions == labels).sum().item()\n",
    "\n",
    "    train_loss /= len(train_loader)\n",
    "    train_accuracy = train_correct / len(train_loader.dataset)\n",
    "\n",
    "    # Validation after each epoch\n",
    "    valid_loss, valid_accuracy = validate(model, val_loader, criterion, device)\n",
    "\n",
    "    # Log metrics to W&B\n",
    "    wandb.log({\n",
    "        \"epoch\": epoch + 1,\n",
    "        \"train_loss\": train_loss,\n",
    "        \"train_accuracy\": train_accuracy,\n",
    "        \"valid_loss\": valid_loss,\n",
    "        \"valid_accuracy\": valid_accuracy,\n",
    "    })\n",
    "\n",
    "    print(f'Epoch {epoch+1}/{n_epochs}, Training Loss: {train_loss:.4f}, Training Accuracy: {train_accuracy:.4f}, Validation Loss: {valid_loss:.4f}, Validation Accuracy: {valid_accuracy:.4f}')\n",
    "\n",
    "    # Save the model if it's the best so far\n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), os.path.join(runs_dir, 'best_model.pt'))\n",
    "\n",
    "print('Training complete.')\n",
    "wandb.finish()  # Finish the W&B run"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b42fc0f8-fc4f-4a65-a495-a9a1cafdbd3a",
   "metadata": {},
   "source": [
    "微调 LLM 路由器涉及训练一个分类器，该分类器根据查询的复杂性确定是否应将查询路由到强模型或弱模型。训练过程首先从 HuggingFace 加载标记数据集，其中包含来自强模型和弱模型的查询及其性能分数。该数据集被转换为 pandas DataFrame 以简化操作。标签是基于性能阈值创建的：在弱模型中得分足够高的查询（例如，得分为 4 或以上）被标记为适合该模型，而较低的得分表明需要强模型。\n",
    "\n",
    "然后使用 train_test_split 将数据分成训练集和验证集，这确保模型在一部分数据上进行训练并在另一部分上进行验证，从而可以评估其在未见过的数据上的性能。为了有效地处理数据，定义了一个自定义的 PyTorch 数据集类，将查询及其标签构建为批次，可以在训练期间使用 DataLoader 实用程序对这些批次进行洗牌和处理。\n",
    "\n",
    "分类器模型是使用 Sentence Transformers 库中的可训练变压器主干构建的，它为输入句子生成嵌入。这些嵌入通过一系列具有 ReLU 激活的完全连接层传递，最终形成为二元分类提供 logit 的单个输出神经元。使用的损失函数是 BCEWithLogitsLoss，它非常适合路由决策等二元分类任务。\n",
    "\n",
    "在每个epoch，模型都会在训练集上进行训练，以最大限度地减少分类损失并提高准确性。训练后，模型的性能在验证集上进行评估，从而可以监控其对新数据的泛化。使用权重和偏差在整个过程中记录训练和验证损失和准确性等性能指标，从而能够实时跟踪和分析模型的进度。\n",
    "\n",
    "当模型训练时，只要与之前的迭代相比，它实现了较低的验证损失，就会保存其状态。此检查点可确保保留模型的最佳版本，有助于避免使用过度拟合训练数据的模型。当所有 epoch 完成时，训练结束，权重和偏差的运行也最终确定，从而巩固了实验结果。然后，经过训练的模型就可以部署在 LLM 路由系统中，它将使用其学到的知识动态地确定每个查询的最佳模型，平衡性能与成本考虑。\n",
    "\n",
    "## 评估LLM Router的性能\n",
    "\n",
    "我们使用两个关键指标——恢复性能差距 (PGR) 和呼叫性能阈值 (CPT)——来评估路由有效性。 PGR 衡量路由系统可以恢复强模型和弱模型之间的性能差距有多大。例如，如果 GPT-4o 达到 100% 的准确率，Mixtral-8x7B 达到 86%，那么达到 93% 的路由模型就可以弥补一半的差距。该系统允许通过调整阈值来调整路由模型，这些阈值定义何时基于查询复杂性和置信度路由到强模型。\n",
    "\n",
    "另一方面，CPT 量化必须路由到强模型以实现所需 PGR 级别的查询的最小百分比。例如，CPT(50%)表示通过一定比例的强模型调用可以弥补一半的性能差距。较低的 CPT 值表明更高效的路由模型，可以通过减少对更昂贵模型的调用来保持高性能。性能/成本权衡图说明了这种平衡，显示了准确性如何响应对强模型的不同程度的依赖。决策者可以使用此图表来确定最佳的成本节约策略，而无需牺牲太多性能。\n",
    "\n",
    "下面是一些计算 CPT(50%) 和 CPT(80%) 分数的代码，以及性能/成本权衡图表，用于显示随着对强模型的更多调用，性能如何提高。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e83a5bb-32e1-41dd-b0c0-39295776a67f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:j0kua5hb) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>CPT_50</td><td>▁</td></tr><tr><td>CPT_80</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>CPT_50</td><td>21.4</td></tr><tr><td>CPT_80</td><td>49</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">CPT_Evaluation</strong> at: <a href='https://wandb.ai/wangrongsheng/router_eval/runs/j0kua5hb' target=\"_blank\">https://wandb.ai/wangrongsheng/router_eval/runs/j0kua5hb</a><br/> View project at: <a href='https://wandb.ai/wangrongsheng/router_eval' target=\"_blank\">https://wandb.ai/wangrongsheng/router_eval</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20241007_225446-j0kua5hb/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:j0kua5hb). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/root/wandb/run-20241007_230154-834sh0yc</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/wangrongsheng/router_eval/runs/834sh0yc' target=\"_blank\">CPT_Evaluation</a></strong> to <a href='https://wandb.ai/wangrongsheng/router_eval' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/wangrongsheng/router_eval' target=\"_blank\">https://wandb.ai/wangrongsheng/router_eval</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/wangrongsheng/router_eval/runs/834sh0yc' target=\"_blank\">https://wandb.ai/wangrongsheng/router_eval/runs/834sh0yc</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.076 MB of 0.076 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>CPT_50</td><td>▁</td></tr><tr><td>CPT_80</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>CPT_50</td><td>21.4</td></tr><tr><td>CPT_80</td><td>49</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">CPT_Evaluation</strong> at: <a href='https://wandb.ai/wangrongsheng/router_eval/runs/834sh0yc' target=\"_blank\">https://wandb.ai/wangrongsheng/router_eval/runs/834sh0yc</a><br/> View project at: <a href='https://wandb.ai/wangrongsheng/router_eval' target=\"_blank\">https://wandb.ai/wangrongsheng/router_eval</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 2 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20241007_230154-834sh0yc/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import nn\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from datasets import load_dataset\n",
    "import wandb\n",
    "\n",
    "# Initialize WandB project\n",
    "wandb.init(project=\"router_eval\", name=\"CPT_Evaluation\")\n",
    "\n",
    "# Define the trained model class and load the model\n",
    "class Classifier(nn.Module):\n",
    "    def __init__(self, transformer_model_name):\n",
    "        super(Classifier, self).__init__()\n",
    "        self.transformer = SentenceTransformer(transformer_model_name)\n",
    "        self.fc1 = nn.Linear(self.transformer.get_sentence_embedding_dimension(), 512)\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.fc3 = nn.Linear(256, 1)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "\n",
    "    def forward(self, sentences):\n",
    "        embeddings = self.transformer.encode(sentences, convert_to_tensor=True)\n",
    "        x = self.relu(self.fc1(embeddings))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        return self.fc3(x)\n",
    "\n",
    "model = Classifier('./all-distilroberta-v1')\n",
    "model.load_state_dict(torch.load('runs/best_model.pt'))\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device).eval()\n",
    "\n",
    "# Load evaluation data\n",
    "dataset = load_dataset(\"./gpt4_dataset\")\n",
    "eval_df = dataset[\"validation\"].to_pandas()\n",
    "sentences_eval = eval_df[\"prompt\"].tolist()\n",
    "labels_eval = eval_df[\"mixtral_score\"].tolist()\n",
    "\n",
    "def calculate_accuracy(predictions, labels):\n",
    "    correct = 0\n",
    "    for pred, label in zip(predictions, labels):\n",
    "        if pred == 1:  # Routed to the strong model\n",
    "            correct += 1  # Always considered correct\n",
    "        elif pred == 0 and label >= 4:  # Routed to the weak model and label indicates correct\n",
    "            correct += 1  # Correct if the label meets the threshold\n",
    "    return correct / len(predictions) if predictions else 0\n",
    "\n",
    "# Generate logits using the model\n",
    "def generate_logits(model, sentences, labels):\n",
    "    logit_buffer = []\n",
    "    for sentence, label in zip(sentences, labels):\n",
    "        with torch.no_grad():\n",
    "            output = model([sentence]).squeeze(1)\n",
    "            prob_strong = torch.sigmoid(output).item()\n",
    "            logit_buffer.append((prob_strong, 1 - prob_strong, label))\n",
    "    return logit_buffer\n",
    "\n",
    "# Evaluate the model across bins\n",
    "def evaluate_model_across_bins(logit_buffer, num_bins):\n",
    "    bin_accuracies = []\n",
    "    for pct in range(1, num_bins + 1):\n",
    "        max_calls = int((pct / num_bins) * len(logit_buffer))\n",
    "        sorted_buffer = sorted(logit_buffer, key=lambda x: x[0], reverse=True)\n",
    "        predictions = [1 if i < max_calls else 0 for i in range(len(sorted_buffer))]\n",
    "        true_labels = [lbl for _, _, lbl in sorted_buffer]\n",
    "        accuracy = calculate_accuracy(predictions, true_labels)\n",
    "        bin_accuracies.append((pct * 100 / num_bins, accuracy))\n",
    "    return bin_accuracies\n",
    "\n",
    "# Plot and log accuracies with matplotlib for 1000-bin charts\n",
    "# def plot_and_log_accuracies(bin_accuracies, title, log_name, target_accuracy=None, cpt=None):\n",
    "#     percentages, accuracies, cpt_values = zip(*bin_accuracies)\n",
    "#     plt.figure()\n",
    "#     plt.plot(percentages, accuracies, marker='o')\n",
    "#     plt.xlabel('% Calls to Strong Model')\n",
    "#     plt.ylabel('Accuracy')\n",
    "#     plt.title(title)\n",
    "#     plt.grid(True)\n",
    "    \n",
    "#     # Add dashed lines for target accuracy and CPT, if provided\n",
    "#     if target_accuracy is not None:\n",
    "#         plt.axhline(y=target_accuracy, color='r', linestyle='--', label='Target Accuracy')\n",
    "#     if cpt is not None:\n",
    "#         plt.axvline(x=cpt, color='g', linestyle='--', label=f'CPT Value ({cpt:.2f})')\n",
    "#         # Annotate the actual CPT value\n",
    "#         plt.text(cpt, target_accuracy, f'{cpt:.4f}', color='g', fontsize=9, ha='right', va='bottom')\n",
    "        \n",
    "#     plt.legend()\n",
    "#     plt.savefig(f\"{log_name}.png\")\n",
    "#     wandb.log({log_name: wandb.Image(f\"{log_name}.png\")})\n",
    "#     plt.close()\n",
    "\n",
    "def plot_and_log_accuracies(bin_accuracies, title, log_name, target_accuracy=None, cpt=None):\n",
    "    percentages, accuracies = zip(*bin_accuracies)  # 修改这里，去掉cpt_values\n",
    "    plt.figure()\n",
    "    plt.plot(percentages, accuracies, marker='o')\n",
    "    plt.xlabel('% Calls to Strong Model')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title(title)\n",
    "    plt.grid(True)\n",
    "    \n",
    "    # 添加目标准确率和CPT值的虚线，如果提供了的话\n",
    "    if target_accuracy is not None:\n",
    "        plt.axhline(y=target_accuracy, color='r', linestyle='--', label='Target Accuracy')\n",
    "    if cpt is not None:\n",
    "        plt.axvline(x=cpt, color='g', linestyle='--', label=f'CPT Value ({cpt:.2f})')\n",
    "        # 标注实际的CPT值\n",
    "        plt.text(cpt, target_accuracy, f'{cpt:.4f}', color='g', fontsize=9, ha='right', va='bottom')\n",
    "        \n",
    "    plt.legend()\n",
    "    plt.savefig(f\"{log_name}.png\")\n",
    "    wandb.log({log_name: wandb.Image(f\"{log_name}.png\")})\n",
    "    plt.close()\n",
    "\n",
    "logit_buffer = generate_logits(model, sentences_eval, labels_eval)\n",
    "\n",
    "bin_accuracies_1000 = evaluate_model_across_bins(logit_buffer, 1000)\n",
    "\n",
    "# Find weak and strong model accuracies\n",
    "weak_accuracy = calculate_accuracy([0] * len(labels_eval), labels_eval)\n",
    "strong_accuracy = calculate_accuracy([1] * len(labels_eval), labels_eval)\n",
    "\n",
    "# Calculate CPT values for 50% and 80% PGR\n",
    "target_accuracy_50 = (strong_accuracy - weak_accuracy) * 0.5 + weak_accuracy\n",
    "target_accuracy_80 = (strong_accuracy - weak_accuracy) * 0.8 + weak_accuracy\n",
    "\n",
    "cpt_50 = min(bin_accuracies_1000, key=lambda x: abs(x[1] - target_accuracy_50))[0]\n",
    "cpt_80 = min(bin_accuracies_1000, key=lambda x: abs(x[1] - target_accuracy_80))[0]\n",
    "\n",
    "# Log CPT values\n",
    "wandb.log({\"CPT_50\": cpt_50, \"CPT_80\": cpt_80})\n",
    "\n",
    "# Plot and log the 1000-bin accuracy charts\n",
    "plot_and_log_accuracies(bin_accuracies_1000, 'CPT 50 Evaluation (1000 Bins)', 'CPT 50 Chart', target_accuracy_50, cpt_50)\n",
    "plot_and_log_accuracies(bin_accuracies_1000, 'CPT 80 Evaluation (1000 Bins)', 'CPT 80 Chart', target_accuracy_80, cpt_80)\n",
    "\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43a481f0-004f-42a6-9f92-eca087f2f045",
   "metadata": {},
   "source": [
    "生成的图表显示了 CPT(50%) 和 CPT(80%) 评估的性能/成本权衡。 CPT(80%) 图表表明，需要对强模型进行近 49% 的调用才能达到实现强弱模型之间性能差距恢复 80% 的目标准确度。 CPT(50%) 图表显示，需要约 21.4% 的强模型调用才能达到 50% 性能差距恢复目标。这些结果显示了使用强模型和实现所需性能水平之间的权衡，表明无需将所有查询路由到强模型即可实现显着的性能提升。\n",
    "\n",
    "## 使用 Weave 评估响应质量\n",
    "\n",
    "为了更深入地了解我们的模型在使用路由器时如何响应，我们对数据集进行了 Weave 评估。 Weave 是一个用于简化评估的强大工具，提供了一种快速直观的方式来可视化模型如何响应各种查询。\n",
    "\n",
    "虽然性能指标通常是主要关注点，但 Weave 更进一步，将个人响应直接记录到交互式仪表板。此设置可以轻松地并排比较响应，从而可以轻松识别不同模型如何处理相同的查询。对具体响应的详细检查不仅突出了每个模型的优点和缺点，而且还提供了可以改进的清晰视图，为机器学习从业者提供了有效改进模型所需的信息。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d8d381b-e55f-4641-bb4a-b84cb5c20873",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m1\u001b[0m of \u001b[1;36m100\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m2\u001b[0m of \u001b[1;36m100\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m3\u001b[0m of \u001b[1;36m100\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m4\u001b[0m of \u001b[1;36m100\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m5\u001b[0m of \u001b[1;36m100\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m6\u001b[0m of \u001b[1;36m100\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">7</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m7\u001b[0m of \u001b[1;36m100\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m8\u001b[0m of \u001b[1;36m100\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">9</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m9\u001b[0m of \u001b[1;36m100\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m10\u001b[0m of \u001b[1;36m100\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">11</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m11\u001b[0m of \u001b[1;36m100\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">12</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m12\u001b[0m of \u001b[1;36m100\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">13</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m13\u001b[0m of \u001b[1;36m100\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">14</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m14\u001b[0m of \u001b[1;36m100\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">15</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m15\u001b[0m of \u001b[1;36m100\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">16</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m16\u001b[0m of \u001b[1;36m100\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">17</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m17\u001b[0m of \u001b[1;36m100\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">18</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m18\u001b[0m of \u001b[1;36m100\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">19</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m19\u001b[0m of \u001b[1;36m100\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m20\u001b[0m of \u001b[1;36m100\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">21</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m21\u001b[0m of \u001b[1;36m100\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">22</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m22\u001b[0m of \u001b[1;36m100\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">23</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m23\u001b[0m of \u001b[1;36m100\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">24</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m24\u001b[0m of \u001b[1;36m100\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">25</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m25\u001b[0m of \u001b[1;36m100\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">26</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m26\u001b[0m of \u001b[1;36m100\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">27</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m27\u001b[0m of \u001b[1;36m100\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">28</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m28\u001b[0m of \u001b[1;36m100\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">29</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m29\u001b[0m of \u001b[1;36m100\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">30</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m30\u001b[0m of \u001b[1;36m100\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">31</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m31\u001b[0m of \u001b[1;36m100\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">32</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m32\u001b[0m of \u001b[1;36m100\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">33</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m33\u001b[0m of \u001b[1;36m100\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">34</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m34\u001b[0m of \u001b[1;36m100\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">35</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m35\u001b[0m of \u001b[1;36m100\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">36</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m36\u001b[0m of \u001b[1;36m100\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">37</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m37\u001b[0m of \u001b[1;36m100\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">38</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m38\u001b[0m of \u001b[1;36m100\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">39</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m39\u001b[0m of \u001b[1;36m100\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">40</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m40\u001b[0m of \u001b[1;36m100\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">41</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m41\u001b[0m of \u001b[1;36m100\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">42</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m42\u001b[0m of \u001b[1;36m100\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">43</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m43\u001b[0m of \u001b[1;36m100\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">44</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m44\u001b[0m of \u001b[1;36m100\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">45</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m45\u001b[0m of \u001b[1;36m100\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">46</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m46\u001b[0m of \u001b[1;36m100\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">47</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m47\u001b[0m of \u001b[1;36m100\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m48\u001b[0m of \u001b[1;36m100\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">49</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m49\u001b[0m of \u001b[1;36m100\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m50\u001b[0m of \u001b[1;36m100\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">51</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m51\u001b[0m of \u001b[1;36m100\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">52</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m52\u001b[0m of \u001b[1;36m100\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">53</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m53\u001b[0m of \u001b[1;36m100\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">54</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m54\u001b[0m of \u001b[1;36m100\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">55</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m55\u001b[0m of \u001b[1;36m100\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">56</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m56\u001b[0m of \u001b[1;36m100\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">57</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m57\u001b[0m of \u001b[1;36m100\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">58</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m58\u001b[0m of \u001b[1;36m100\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">59</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m59\u001b[0m of \u001b[1;36m100\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">60</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m60\u001b[0m of \u001b[1;36m100\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">61</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m61\u001b[0m of \u001b[1;36m100\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">62</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m62\u001b[0m of \u001b[1;36m100\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">63</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m63\u001b[0m of \u001b[1;36m100\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">64</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m64\u001b[0m of \u001b[1;36m100\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">65</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m65\u001b[0m of \u001b[1;36m100\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">66</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m66\u001b[0m of \u001b[1;36m100\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">67</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m67\u001b[0m of \u001b[1;36m100\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">68</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m68\u001b[0m of \u001b[1;36m100\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">69</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m69\u001b[0m of \u001b[1;36m100\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">70</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m70\u001b[0m of \u001b[1;36m100\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">71</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m71\u001b[0m of \u001b[1;36m100\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">72</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m72\u001b[0m of \u001b[1;36m100\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">73</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m73\u001b[0m of \u001b[1;36m100\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">74</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m74\u001b[0m of \u001b[1;36m100\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">75</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m75\u001b[0m of \u001b[1;36m100\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">76</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m76\u001b[0m of \u001b[1;36m100\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">77</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m77\u001b[0m of \u001b[1;36m100\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">78</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m78\u001b[0m of \u001b[1;36m100\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">79</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m79\u001b[0m of \u001b[1;36m100\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">80</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m80\u001b[0m of \u001b[1;36m100\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">81</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m81\u001b[0m of \u001b[1;36m100\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">82</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m82\u001b[0m of \u001b[1;36m100\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">83</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m83\u001b[0m of \u001b[1;36m100\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">84</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m84\u001b[0m of \u001b[1;36m100\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">85</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m85\u001b[0m of \u001b[1;36m100\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">86</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m86\u001b[0m of \u001b[1;36m100\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">87</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m87\u001b[0m of \u001b[1;36m100\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">88</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m88\u001b[0m of \u001b[1;36m100\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">89</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m89\u001b[0m of \u001b[1;36m100\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">90</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m90\u001b[0m of \u001b[1;36m100\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">91</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m91\u001b[0m of \u001b[1;36m100\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">92</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m92\u001b[0m of \u001b[1;36m100\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">93</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m93\u001b[0m of \u001b[1;36m100\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">94</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m94\u001b[0m of \u001b[1;36m100\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">95</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m95\u001b[0m of \u001b[1;36m100\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">96</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m96\u001b[0m of \u001b[1;36m100\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">97</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m97\u001b[0m of \u001b[1;36m100\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">98</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m98\u001b[0m of \u001b[1;36m100\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">99</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m99\u001b[0m of \u001b[1;36m100\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m100\u001b[0m of \u001b[1;36m100\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluation summary\n",
       "<span style=\"font-weight: bold\">{</span>\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'match_score'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'match'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'true_count'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">77</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'true_fraction'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.77</span><span style=\"font-weight: bold\">}}</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'model_latency'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'mean'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.4640502405166626</span><span style=\"font-weight: bold\">}</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluation summary\n",
       "\u001b[1m{\u001b[0m\n",
       "    \u001b[32m'match_score'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'match'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'true_count'\u001b[0m: \u001b[1;36m77\u001b[0m, \u001b[32m'true_fraction'\u001b[0m: \u001b[1;36m0.77\u001b[0m\u001b[1m}\u001b[0m\u001b[1m}\u001b[0m,\n",
       "    \u001b[32m'model_latency'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'mean'\u001b[0m: \u001b[1;36m0.4640502405166626\u001b[0m\u001b[1m}\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🍩 https://wandb.ai/wangrongsheng/router-example/r/call/01926787-8764-72e3-9104-d95eee2e19df\n",
      "Evaluation complete.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import pandas as pd\n",
    "import weave\n",
    "from weave import Evaluation\n",
    "import asyncio\n",
    "from datasets import load_dataset\n",
    "from weave import Dataset\n",
    "import nest_asyncio  # 导入 nest_asyncio 模块\n",
    "\n",
    "# 应用 nest_asyncio.patch() 来修补当前环境，允许在已有事件循环中运行 asyncio.run()\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# Define the classifier model with a trainable transformer backbone\n",
    "class Classifier(nn.Module):\n",
    "    def __init__(self, transformer_model_name):\n",
    "        super(Classifier, self).__init__()\n",
    "        self.transformer = SentenceTransformer(transformer_model_name)\n",
    "        self.transformer.train()\n",
    "        self.fc1 = nn.Linear(self.transformer.get_sentence_embedding_dimension(), 512)\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.fc3 = nn.Linear(256, 1)  # Single output neuron for binary classification\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, sentences):\n",
    "        embeddings = self.transformer.encode(sentences, convert_to_tensor=True)  # Generate embeddings\n",
    "        x = self.relu(self.fc1(embeddings))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        logits = self.fc3(x)  # Output single logit for binary classification\n",
    "        return logits\n",
    "\n",
    "# Sample alpha threshold for routing\n",
    "alpha = 0.23591  # Adjust this value based on your routing needs\n",
    "\n",
    "# Initialize the classifier model with the desired transformer\n",
    "transformer_model_name = 'all-distilroberta-v1'  # 注意这里的路径是否正确\n",
    "model = Classifier(transformer_model_name=transformer_model_name)\n",
    "model.load_state_dict(torch.load('runs/best_model.pt'))\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "# Load dataset from Hugging Face and convert to pandas dataframe\n",
    "dataset = load_dataset(\"gpt4_dataset\")  # 注意这里是否需要本地路径或远程名称\n",
    "val_df = dataset[\"validation\"].to_pandas()\n",
    "\n",
    "# Initialize Weave\n",
    "weave.init('router-example')\n",
    "\n",
    "# Define a scoring function that checks if the chosen response matches the expected one\n",
    "@weave.op()\n",
    "def match_score(expected: str, model_output: dict) -> dict:\n",
    "    # Check if the chosen response matches the expected response\n",
    "    return {'match': expected == model_output['generated_text']}\n",
    "\n",
    "# Create evaluation examples directly from the dataframe for speed\n",
    "examples = [\n",
    "    {\n",
    "        \"prompt\": row['prompt'],\n",
    "        \"expected\": row['mixtral_response'] if row['mixtral_score'] >= 4 else row['gpt4_response'],\n",
    "        \"gpt4_response\": row['gpt4_response'],\n",
    "        \"mixtral_response\": row['mixtral_response'],\n",
    "    }\n",
    "    for _, row in val_df.head(100).iterrows()  # just evaluate 100 samples \n",
    "]\n",
    "\n",
    "# Create a Dataset object with examples\n",
    "dataset_obj = Dataset(name='gpt4_dataset_example', rows=examples)\n",
    "\n",
    "@weave.op()\n",
    "def run_inference(prompt: str, gpt4_response: str, mixtral_response: str) -> dict:\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        # Forward pass through classifier to get routing score\n",
    "        logits = model([prompt]).squeeze()\n",
    "        score = torch.sigmoid(logits).item()  # Convert logit to probability score between 0 and 1\n",
    "\n",
    "        # Decision logic based on score and alpha\n",
    "        chosen_response = gpt4_response if score > alpha else mixtral_response\n",
    "\n",
    "    # Return the chosen response\n",
    "    return {\n",
    "        'generated_text': chosen_response,\n",
    "    }\n",
    "\n",
    "# Create an evaluation object with examples and the scoring function\n",
    "evaluation = Evaluation(dataset=dataset_obj, scorers=[match_score])\n",
    "\n",
    "# Run the evaluation asynchronously on the function\n",
    "# 注意这里的实现方式，以适应已经在运行的事件循环\n",
    "coroutine = evaluation.evaluate(run_inference)\n",
    "\n",
    "try:\n",
    "    # 使用 await 直接等待异步函数的结果\n",
    "    result = asyncio.run(coroutine)\n",
    "except RuntimeError:\n",
    "    # 如果仍然遇到事件循环已经存在的错误，可以尝试以下方法创建一个新的任务并等待它完成\n",
    "    loop = asyncio.get_event_loop()\n",
    "    task = loop.create_task(coroutine)\n",
    "    result = loop.run_until_complete(task)\n",
    "\n",
    "print('Evaluation complete.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8787443-2bef-48dd-a229-df93a8b21909",
   "metadata": {},
   "source": [
    "- https://wandb.ai/byyoung3/ML_NEWS3/reports/How-to-train-and-evaluate-an-LLM-router--Vmlldzo5MjU0MTA1\n",
    "- https://github.com/lm-sys/RouteLLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5172c074-a389-4f1f-a499-cf97c4a0d6a7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
