{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "- SBert文档：https://www.sbert.net/\n",
        "- Huggingface：https://huggingface.co/sentence-transformers"
      ],
      "metadata": {
        "id": "-FwxpwXE5Tbd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Computing Embeddings"
      ],
      "metadata": {
        "id": "Ap7NXCZD6FKs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sentence-transformers -q"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lp7qykJl6W2Y",
        "outputId": "e518e259-e88c-4134-ea84-5c90b0bebaa2"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/249.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m249.1/249.1 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9P82U0y65C3-",
        "outputId": "cb9d3f05-16bf-4148-8570-3a4b0b70582b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(3, 384)\n",
            "tensor([[1.0000, 0.6660, 0.1046],\n",
            "        [0.6660, 1.0000, 0.1411],\n",
            "        [0.1046, 0.1411, 1.0000]])\n"
          ]
        }
      ],
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "# 1. Load a pretrained Sentence Transformer model\n",
        "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "\n",
        "# The sentences to encode\n",
        "sentences = [\n",
        "    \"The weather is lovely today.\",\n",
        "    \"It's so sunny outside!\",\n",
        "    \"He drove to the stadium.\",\n",
        "]\n",
        "\n",
        "# 2. Calculate embeddings by calling model.encode()\n",
        "embeddings = model.encode(sentences)\n",
        "print(embeddings.shape)\n",
        "# [3, 384]\n",
        "\n",
        "# 3. Calculate the embedding similarities\n",
        "similarities = model.similarity(embeddings, embeddings)\n",
        "print(similarities)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "# 1. Load a pretrained Sentence Transformer model\n",
        "model = SentenceTransformer(\"bert-base-chinese\")\n",
        "\n",
        "# The sentences to encode\n",
        "sentences = [\n",
        "    \"今天天气真好.\",\n",
        "    \"外面真晴朗\",\n",
        "    \"他正在骑车\",\n",
        "]\n",
        "\n",
        "# 2. Calculate embeddings by calling model.encode()\n",
        "embeddings = model.encode(sentences)\n",
        "print(embeddings.shape)\n",
        "# [3, 768]\n",
        "\n",
        "# 3. Calculate the embedding similarities\n",
        "similarities = model.similarity(embeddings, embeddings)\n",
        "print(similarities)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5aJQQcu2_ddX",
        "outputId": "a9489018-7018-4ab0-9e9a-2bf24a2ecdbd"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:sentence_transformers.SentenceTransformer:No sentence-transformers model found with name bert-base-chinese. Creating a new one with mean pooling.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(3, 768)\n",
            "tensor([[1.0000, 0.8643, 0.6566],\n",
            "        [0.8643, 1.0000, 0.6867],\n",
            "        [0.6566, 0.6867, 1.0000]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Semantic Textual Similarity"
      ],
      "metadata": {
        "id": "F8wTJY2f6hwk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "\n",
        "# Two lists of sentences\n",
        "sentences1 = [\n",
        "    \"The new movie is awesome\",\n",
        "    \"The cat sits outside\",\n",
        "    \"A man is playing guitar\",\n",
        "]\n",
        "\n",
        "sentences2 = [\n",
        "    \"The dog plays in the garden\",\n",
        "    \"The new movie is so great\",\n",
        "    \"A woman watches TV\",\n",
        "]\n",
        "\n",
        "# Compute embeddings for both lists\n",
        "embeddings1 = model.encode(sentences1)\n",
        "embeddings2 = model.encode(sentences2)\n",
        "\n",
        "# Compute cosine similarities\n",
        "similarities = model.similarity(embeddings1, embeddings2)\n",
        "\n",
        "# Output the pairs with their score\n",
        "for idx_i, sentence1 in enumerate(sentences1):\n",
        "    print(sentence1)\n",
        "    for idx_j, sentence2 in enumerate(sentences2):\n",
        "        print(f\" - {sentence2: <30}: {similarities[idx_i][idx_j]:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zsg41C046STv",
        "outputId": "c63f2714-2222-465c-a994-e2d4b78e8add"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The new movie is awesome\n",
            " - The dog plays in the garden   : 0.0543\n",
            " - The new movie is so great     : 0.8939\n",
            " - A woman watches TV            : -0.0502\n",
            "The cat sits outside\n",
            " - The dog plays in the garden   : 0.2838\n",
            " - The new movie is so great     : -0.0029\n",
            " - A woman watches TV            : 0.1310\n",
            "A man is playing guitar\n",
            " - The dog plays in the garden   : 0.2277\n",
            " - The new movie is so great     : -0.0136\n",
            " - A woman watches TV            : -0.0327\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "model = SentenceTransformer(\"bert-base-chinese\")\n",
        "\n",
        "# Two lists of sentences\n",
        "sentences1 = [\n",
        "    \"新电影真好看\",\n",
        "    \"猫在外面呆着\",\n",
        "    \"一个男人正在弹吉他\",\n",
        "]\n",
        "\n",
        "sentences2 = [\n",
        "    \"狗正在花园玩\",\n",
        "    \"新电影真好\",\n",
        "    \"一个女人正在看电视\",\n",
        "]\n",
        "\n",
        "# Compute embeddings for both lists\n",
        "embeddings1 = model.encode(sentences1)\n",
        "embeddings2 = model.encode(sentences2)\n",
        "\n",
        "# Compute cosine similarities\n",
        "similarities = model.similarity(embeddings1, embeddings2)\n",
        "\n",
        "# Output the pairs with their score\n",
        "for idx_i, sentence1 in enumerate(sentences1):\n",
        "    print(sentence1)\n",
        "    for idx_j, sentence2 in enumerate(sentences2):\n",
        "        print(f\" - {sentence2: <30}: {similarities[idx_i][idx_j]:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "phAhIV35_v8Q",
        "outputId": "6f0f8ffd-9ce7-4378-c53a-e751d85d9632"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:sentence_transformers.SentenceTransformer:No sentence-transformers model found with name bert-base-chinese. Creating a new one with mean pooling.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "新电影真好看\n",
            " - 狗正在花园玩                        : 0.6958\n",
            " - 新电影真好                         : 0.9713\n",
            " - 一个女人正在看电视                     : 0.7666\n",
            "猫在外面呆着\n",
            " - 狗正在花园玩                        : 0.8208\n",
            " - 新电影真好                         : 0.6799\n",
            " - 一个女人正在看电视                     : 0.7836\n",
            "一个男人正在弹吉他\n",
            " - 狗正在花园玩                        : 0.7405\n",
            " - 新电影真好                         : 0.7076\n",
            " - 一个女人正在看电视                     : 0.9134\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Semantic Search"
      ],
      "metadata": {
        "id": "FzLxOPpM6qjN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "This is a simple application for sentence embeddings: semantic search\n",
        "\n",
        "We have a corpus with various sentences. Then, for a given query sentence,\n",
        "we want to find the most similar sentence in this corpus.\n",
        "\n",
        "This script outputs for various queries the top 5 most similar sentences in the corpus.\n",
        "\"\"\"\n",
        "\n",
        "import torch\n",
        "\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "embedder = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "\n",
        "# Corpus with example sentences\n",
        "corpus = [\n",
        "    \"A man is eating food.\",\n",
        "    \"A man is eating a piece of bread.\",\n",
        "    \"The girl is carrying a baby.\",\n",
        "    \"A man is riding a horse.\",\n",
        "    \"A woman is playing violin.\",\n",
        "    \"Two men pushed carts through the woods.\",\n",
        "    \"A man is riding a white horse on an enclosed ground.\",\n",
        "    \"A monkey is playing drums.\",\n",
        "    \"A cheetah is running behind its prey.\",\n",
        "]\n",
        "# Use \"convert_to_tensor=True\" to keep the tensors on GPU (if available)\n",
        "corpus_embeddings = embedder.encode(corpus, convert_to_tensor=True)\n",
        "\n",
        "# Query sentences:\n",
        "queries = [\n",
        "    \"A man is eating pasta.\",\n",
        "    \"Someone in a gorilla costume is playing a set of drums.\",\n",
        "    \"A cheetah chases prey on across a field.\",\n",
        "]\n",
        "\n",
        "# Find the closest 5 sentences of the corpus for each query sentence based on cosine similarity\n",
        "top_k = min(5, len(corpus))\n",
        "for query in queries:\n",
        "    query_embedding = embedder.encode(query, convert_to_tensor=True)\n",
        "\n",
        "    # We use cosine-similarity and torch.topk to find the highest 5 scores\n",
        "    similarity_scores = embedder.similarity(query_embedding, corpus_embeddings)[0]\n",
        "    scores, indices = torch.topk(similarity_scores, k=top_k)\n",
        "\n",
        "    print(\"\\nQuery:\", query)\n",
        "    print(\"Top 5 most similar sentences in corpus:\")\n",
        "\n",
        "    for score, idx in zip(scores, indices):\n",
        "        print(corpus[idx], f\"(Score: {score:.4f})\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EYh7ISU36mx-",
        "outputId": "9b08709e-ca17-4b0f-9452-3fcc91261f91"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Query: A man is eating pasta.\n",
            "Top 5 most similar sentences in corpus:\n",
            "A man is eating food. (Score: 0.7035)\n",
            "A man is eating a piece of bread. (Score: 0.5272)\n",
            "A man is riding a horse. (Score: 0.1889)\n",
            "A man is riding a white horse on an enclosed ground. (Score: 0.1047)\n",
            "A cheetah is running behind its prey. (Score: 0.0980)\n",
            "\n",
            "Query: Someone in a gorilla costume is playing a set of drums.\n",
            "Top 5 most similar sentences in corpus:\n",
            "A monkey is playing drums. (Score: 0.6433)\n",
            "A woman is playing violin. (Score: 0.2564)\n",
            "A man is riding a horse. (Score: 0.1389)\n",
            "A man is riding a white horse on an enclosed ground. (Score: 0.1191)\n",
            "A cheetah is running behind its prey. (Score: 0.1080)\n",
            "\n",
            "Query: A cheetah chases prey on across a field.\n",
            "Top 5 most similar sentences in corpus:\n",
            "A cheetah is running behind its prey. (Score: 0.8253)\n",
            "A man is eating food. (Score: 0.1399)\n",
            "A monkey is playing drums. (Score: 0.1292)\n",
            "A man is riding a white horse on an enclosed ground. (Score: 0.1097)\n",
            "A man is riding a horse. (Score: 0.0650)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Retrieve & Re-Rank"
      ],
      "metadata": {
        "id": "XU5-ZiCN68qI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "model = SentenceTransformer(\"multi-qa-mpnet-base-dot-v1\")\n",
        "\n",
        "docs = [\n",
        "    \"My first paragraph. That contains information\",\n",
        "    \"Python is a programming language.\",\n",
        "]\n",
        "document_embeddings = model.encode(docs)\n",
        "\n",
        "query = \"What is Python?\"\n",
        "query_embedding = model.encode(query)\n",
        "\n",
        "similarity_scores = embedder.similarity(query_embedding, document_embeddings)[0]\n",
        "scores, indices = torch.topk(similarity_scores, k=1)\n",
        "\n",
        "print(scores, indices)\n",
        "print(docs[indices])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jGXIANug6ukl",
        "outputId": "708a2e15-fcd1-4b59-cd14-9c08e6255188"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.8842]) tensor([1])\n",
            "Python is a programming language.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Paraphrase Mining\n",
        "\n",
        "Paraphrase mining is the task of finding paraphrases (texts with identical /similar meaning) in a large corpus of sentences. In `Semantic Textual Similarity` we saw a simplified version of finding paraphrases in a list of sentences. The approach presented there used a brute-force approach to score and rank all pairs."
      ],
      "metadata": {
        "id": "zn_T8vFh9EMe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "from sentence_transformers.util import paraphrase_mining\n",
        "\n",
        "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "\n",
        "# Single list of sentences - Possible tens of thousands of sentences\n",
        "sentences = [\n",
        "    \"The cat sits outside\",\n",
        "    \"A man is playing guitar\",\n",
        "    \"I love pasta\",\n",
        "    \"The new movie is awesome\",\n",
        "    \"The cat plays in the garden\",\n",
        "    \"A woman watches TV\",\n",
        "    \"The new movie is so great\",\n",
        "    \"Do you like pizza?\",\n",
        "]\n",
        "\n",
        "paraphrases = paraphrase_mining(model, sentences)\n",
        "\n",
        "for paraphrase in paraphrases[0:10]:\n",
        "    score, i, j = paraphrase\n",
        "    print(\"{} \\t\\t {} \\t\\t Score: {:.4f}\".format(sentences[i], sentences[j], score))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HAnn8up57DZ2",
        "outputId": "86655d8d-a4a8-444a-8b8c-f51485ee2974"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The new movie is awesome \t\t The new movie is so great \t\t Score: 0.8939\n",
            "The cat sits outside \t\t The cat plays in the garden \t\t Score: 0.6788\n",
            "I love pasta \t\t Do you like pizza? \t\t Score: 0.5096\n",
            "I love pasta \t\t The new movie is so great \t\t Score: 0.2560\n",
            "I love pasta \t\t The new movie is awesome \t\t Score: 0.2440\n",
            "A man is playing guitar \t\t The cat plays in the garden \t\t Score: 0.2105\n",
            "The new movie is awesome \t\t Do you like pizza? \t\t Score: 0.1969\n",
            "The new movie is so great \t\t Do you like pizza? \t\t Score: 0.1692\n",
            "The cat sits outside \t\t A woman watches TV \t\t Score: 0.1310\n",
            "The cat plays in the garden \t\t Do you like pizza? \t\t Score: 0.0900\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Image Search"
      ],
      "metadata": {
        "id": "NfmNykA99fzs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "from PIL import Image\n",
        "\n",
        "# Load CLIP model\n",
        "model = SentenceTransformer(\"clip-ViT-B-32\")\n",
        "\n",
        "# Encode an image:\n",
        "img_emb = model.encode(Image.open(\"dog-in-the-snow.png\"))\n",
        "\n",
        "# Encode text descriptions\n",
        "text_emb = model.encode(\n",
        "    [\"Two dogs in the snow\", \"A cat on a table\", \"A picture of London at night\"]\n",
        ")\n",
        "\n",
        "# Compute similarities\n",
        "similarity_scores = model.similarity(img_emb, text_emb)\n",
        "print(similarity_scores)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e2rktszr9gYu",
        "outputId": "5f23c8a4-f8de-4a17-9663-e6139ca3e3d6"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.2651, 0.1511, 0.1240]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jaoMohIm9j_y"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}