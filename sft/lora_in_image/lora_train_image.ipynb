{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "14e62630-7a9d-4cc2-9527-af81e67d4427",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import os\n",
    "\n",
    "result = subprocess.run('bash -c \"source /etc/network_turbo && env | grep proxy\"', shell=True, capture_output=True, text=True)\n",
    "output = result.stdout\n",
    "for line in output.splitlines():\n",
    "    if '=' in line:\n",
    "        var, value = line.split('=', 1)\n",
    "        os.environ[var] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb2128db-2aaf-4796-ab52-05b0bb7c5aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os  \n",
    "import torch  \n",
    "from torch import optim, nn  \n",
    "from PIL import Image  \n",
    "from torch.utils import data  \n",
    "from torchvision import models  \n",
    "from torchvision.transforms import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "26dfca30-7e9f-4d67-9833-fcd263a4d24c",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([  \n",
    "    transforms.Resize(256),  \n",
    "    transforms.CenterCrop(224),  \n",
    "    transforms.ToTensor(),  \n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),  \n",
    "])  \n",
    "\n",
    "class LoraDataset(data.Dataset):  \n",
    "    def __init__(self, data_path=\"data\"):  \n",
    "        categories = models.VGG19_Weights.IMAGENET1K_V1.value.meta[\"categories\"]  \n",
    "        self.files = []  \n",
    "        self.labels = []  \n",
    "        for dir in os.listdir(data_path):  \n",
    "            if dir == \".ipynb_checkpoints\":  # 忽略检查点文件夹\n",
    "                continue\n",
    "            dirname = os.path.join(data_path, dir)  \n",
    "            for file in os.listdir(dirname):  \n",
    "                if file == \".ipynb_checkpoints\":  # 忽略检查点文件夹\n",
    "                    continue\n",
    "                self.files.append(os.path.join(dirname, file))  \n",
    "                self.labels.append(categories.index(dir))  \n",
    "  \n",
    "    def __getitem__(self, item):  \n",
    "        image = Image.open(self.files[item]).convert(\"RGB\")  \n",
    "        label = torch.zeros(1000, dtype=torch.float64)  \n",
    "        label[self.labels[item]] = 1.  \n",
    "        return transform(image), label  \n",
    "  \n",
    "    def __len__(self):  \n",
    "        return len(self.files)\n",
    "\n",
    "class TestLoraDataset(data.Dataset):  \n",
    "    def __init__(self, data_path=\"test\"):  \n",
    "        categories = models.VGG19_Weights.IMAGENET1K_V1.value.meta[\"categories\"]  \n",
    "        self.files = []  \n",
    "        self.labels = []  \n",
    "        for dir in os.listdir(data_path):  \n",
    "            if dir == \".ipynb_checkpoints\":  # 忽略检查点文件夹\n",
    "                continue\n",
    "            dirname = os.path.join(data_path, dir)  \n",
    "            for file in os.listdir(dirname):  \n",
    "                if file == \".ipynb_checkpoints\":  # 忽略检查点文件夹\n",
    "                    continue\n",
    "                self.files.append(os.path.join(dirname, file))  \n",
    "                self.labels.append(categories.index(dir))  \n",
    "  \n",
    "    def __getitem__(self, item):  \n",
    "        image = Image.open(self.files[item]).convert(\"RGB\")  \n",
    "        label = torch.zeros(1000, dtype=torch.float64)  \n",
    "        label[self.labels[item]] = 1.  \n",
    "        return transform(image), label  \n",
    "  \n",
    "    def __len__(self):  \n",
    "        return len(self.files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ea834707-f83b-40e0-aaac-0998f342df6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Lora(nn.Module):  \n",
    "    def __init__(self, m, n, rank=10):  \n",
    "        super().__init__()  \n",
    "        self.m = m  \n",
    "        self.A = nn.Parameter(torch.randn(m, rank))  \n",
    "        self.B = nn.Parameter(torch.zeros(rank, n))  \n",
    "  \n",
    "    def forward(self, inputs):  \n",
    "        inputs = inputs.view(-1, self.m)  \n",
    "        return torch.mm(torch.mm(inputs, self.A), self.B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e0020b2c-36a8-4fd2-b225-37b1ed5a43dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.0007559689621909153\n",
      "loss: 0.0003224081709352807\n",
      "loss: 0.00014359283219770683\n",
      "loss: 6.724195399480475e-05\n",
      "loss: 3.321674641180531e-05\n",
      "loss: 1.7324294863859297e-05\n",
      "loss: 9.417301801780317e-06\n",
      "loss: 5.4040791042098135e-06\n",
      "loss: 3.258360493418877e-06\n",
      "loss: 2.0265475815980003e-06\n"
     ]
    }
   ],
   "source": [
    "# 加载底模和lora  \n",
    "vgg19 = models.vgg19(models.VGG19_Weights.IMAGENET1K_V1)  \n",
    "for params in vgg19.parameters():  \n",
    "    params.requires_grad = False  \n",
    "vgg19.eval()  \n",
    "lora = Lora(224 * 224 * 3, 1000)\n",
    "\n",
    "batch_size = 16\n",
    "lr = 1e-4\n",
    "# 加载数据  \n",
    "lora_loader = data.DataLoader(LoraDataset(), batch_size=batch_size, shuffle=True)  \n",
    "# 加载优化器  \n",
    "optimizer = optim.Adam(lora.parameters(), lr=lr)  \n",
    "# 定义损失  \n",
    "loss_fn = nn.CrossEntropyLoss()  \n",
    "#  训练轮次\n",
    "epochs = 10 \n",
    "# 训练  \n",
    "for epoch in range(epochs):  \n",
    "    for image, label in lora_loader:  \n",
    "        # 正向传播  \n",
    "        pred = vgg19(image) + lora(image)  \n",
    "        loss = loss_fn(pred, label)  \n",
    "        # 反向传播  \n",
    "        loss.backward()  \n",
    "        # 更新参数  \n",
    "        optimizer.step()  \n",
    "        optimizer.zero_grad()  \n",
    "        print(f\"loss: {loss.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c34d57fa-f2d8-4e49-8fee-3306b3a802e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 测试  \n",
    "# for image, _ in lora_loader:  \n",
    "#     pred = vgg19(image) + lora(image)  \n",
    "#     print(pred)\n",
    "#     idx = torch.argmax(pred, dim=1).item()  \n",
    "#     category = models.VGG19_Weights.IMAGENET1K_V1.value.meta[\"categories\"][idx]  \n",
    "#     print(category)\n",
    "# torch.save(lora.state_dict(), 'lora.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1c92e3bb-f73b-463a-a17b-4241e909e81b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "goldfish\n",
      "goldfish\n",
      "goldfish\n"
     ]
    }
   ],
   "source": [
    "test_lora_loader = data.DataLoader(TestLoraDataset(), batch_size=batch_size, shuffle=True) \n",
    "\n",
    "for image, _ in test_lora_loader:  \n",
    "    pred = vgg19(image) + lora(image)  \n",
    "    \n",
    "    # 找到每个样本的最大值索引\n",
    "    idx = torch.argmax(pred, dim=1)  \n",
    "    # 遍历每个样本的索引\n",
    "    for i in range(len(idx)):\n",
    "        category = models.VGG19_Weights.IMAGENET1K_V1.value.meta[\"categories\"][idx[i].item()]  \n",
    "        print(category)\n",
    "\n",
    "torch.save(lora.state_dict(), 'lora.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b51c21d4-6535-4df3-bbe8-cb4628cb9b68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.png: goldfish\n",
      "3.png: goldfish\n",
      "1.png: goldfish\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from torchvision import models, transforms\n",
    "from PIL import Image\n",
    "import requests\n",
    "\n",
    "# 加载模型\n",
    "vgg19 = models.vgg19(weights=models.VGG19_Weights.IMAGENET1K_V1)\n",
    "vgg19.eval()  # 设置为评估模式\n",
    "\n",
    "# 定义图像预处理\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# 读取标签\n",
    "LABELS_URL = \"https://raw.githubusercontent.com/anishathalye/imagenet-simple-labels/master/imagenet-simple-labels.json\"\n",
    "labels = requests.get(LABELS_URL).json()\n",
    "\n",
    "# 推理并输出结果\n",
    "test_folder = 'test/goldfish'\n",
    "for filename in os.listdir(test_folder):\n",
    "    if filename.endswith(('.jpg', '.png', '.jpeg')):\n",
    "        img_path = os.path.join(test_folder, filename)\n",
    "        image = Image.open(img_path)\n",
    "        image = preprocess(image).unsqueeze(0)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            output = vgg19(image)\n",
    "            _, predicted = torch.max(output, 1)\n",
    "            print(f\"{filename}: {labels[predicted.item()]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f0cc2a3-1424-435e-86dd-285d4f2978bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
